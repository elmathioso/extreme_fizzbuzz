{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03020dbd-9951-43c0-a7aa-1ab332d9b214",
   "metadata": {},
   "source": [
    "# Step 1: Create SOTA MNIST Model\n",
    "\n",
    "An absolutely unecessary appproach.\n",
    "\n",
    "Create a dual handwritten-digit FizzBuzz model.\n",
    "\n",
    "This program creates a SOTA-like MNIST model, then creates a new model\n",
    "with a dual copy of the MNIST model with FizzBuzz output flags.\n",
    "\n",
    "This code is based on the following code sources:\n",
    "- The [Keras MNIST example](https://www.tensorflow.org/datasets/keras_example) (used in the dataset preparation)\n",
    "- The [MNIST CNN SOTA model code](https://medium.com/@BrendanArtley/mnist-keras-simple-cnn-99-6-731b624aee7f) from [Brendan Artley](https://github.com/brendanartley/Medium-Article-Code/blob/main/code/mnist-keras-cnn-99-6.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df0b6b2-3cdf-4ef4-8a12-f958ca2fe53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import clone_model, Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699c4f0a-212d-4161-a0fb-a1537447e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 16:50:27.078796: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-14 16:50:27.121127: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-14 16:50:27.121153: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-14 16:50:27.123758: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-14 16:50:27.123786: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-14 16:50:27.123795: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-14 16:50:27.364160: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-14 16:50:27.364205: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-14 16:50:27.364211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-14 16:50:27.364230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-14 16:50:27.364245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3542 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load embedded MNIST data\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "# Normalize training data\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Normalize testing data\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Also manually load data for easy interactivity\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afc68b-68b9-4415-90a9-6fe3d5b00788",
   "metadata": {},
   "source": [
    "## Create SOTA Model \n",
    "\n",
    "Create a CNN model to evaluate the handwwritten digits.\n",
    "\n",
    "From [Brendan Artley](https://medium.com/@BrendanArtley/mnist-keras-simple-cnn-99-6-731b624aee7f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d7a80b-ad5b-4b99-b1c2-78f39c2f172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last', input_shape=(28,28, 1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='relu', data_format='channels_last'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid', strides=2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3a2a90-2537-4a41-ab8a-d6ba27faca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2024-10-14 16:50:58.190760: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-10-14 16:51:00.041461: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "2024-10-14 16:51:01.540124: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f71e001ba10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-14 16:51:01.540156: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2024-10-14 16:51:01.550388: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728924661.616647   67501 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 15s 18ms/step - loss: 0.1872 - sparse_categorical_accuracy: 0.9451 - val_loss: 0.2862 - val_sparse_categorical_accuracy: 0.9222\n",
      "Epoch 2/15\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.0547 - val_sparse_categorical_accuracy: 0.9841\n",
      "Epoch 3/15\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.0292 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 4/15\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0419 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9917\n",
      "Epoch 5/15\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0203 - val_sparse_categorical_accuracy: 0.9944\n",
      "Epoch 6/15\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0256 - val_sparse_categorical_accuracy: 0.9926\n",
      "Epoch 7/15\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0266 - val_sparse_categorical_accuracy: 0.9923\n",
      "Epoch 8/15\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.0309 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0260 - val_sparse_categorical_accuracy: 0.9929\n",
      "Epoch 9/15\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0269 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9933\n",
      "Epoch 10/15\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0244 - val_sparse_categorical_accuracy: 0.9925\n",
      "Epoch 11/15\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0237 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0186 - val_sparse_categorical_accuracy: 0.9946\n",
      "Epoch 12/15\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0226 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0209 - val_sparse_categorical_accuracy: 0.9940\n",
      "Epoch 13/15\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0196 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.0196 - val_sparse_categorical_accuracy: 0.9941\n",
      "Epoch 14/15\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.0335 - val_sparse_categorical_accuracy: 0.9906\n",
      "Epoch 15/15\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0183 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.0244 - val_sparse_categorical_accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f72e1548310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=15,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90aa6eca-085a-49fe-8cca-00effa6bd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('fizzbuzz_mnist_single.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4040e5fb-1564-4d1b-a0b1-e91150b6e170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Results:\n",
      "[[7.2236765e-14 5.3631177e-13 1.6973480e-13 4.7385598e-14 5.8497504e-12\n",
      "  8.7207130e-11 1.0000000e+00 7.5902894e-17 5.6532400e-12 1.0887482e-17]]\n",
      "Value: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test model\n",
    "\n",
    "# Pick a random digit\n",
    "# Note: Uses x_test for future validation; x_train used for smoke test\n",
    "x = random.randint(0, len(x_train))  \n",
    "v = x_train[x]\n",
    "res = model.predict(np.expand_dims(v, axis=0))\n",
    "print(\"Results:\")\n",
    "print(res)\n",
    "\n",
    "# print highest digit\n",
    "print(\"Value:\", np.argmax(res))\n",
    "\n",
    "fig, axes = plt.subplots(1,1,figsize=(3,3))\n",
    "\n",
    "axes.imshow(v)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ea63e21-27a2-4c94-a47f-c628bd0a43cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 28, 28, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 28, 28, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 14, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 1024)              4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2213610 (8.44 MB)\n",
      "Trainable params: 2210154 (8.43 MB)\n",
      "Non-trainable params: 3456 (13.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# If necessary, reload model for below debugging \n",
    "# model = tf.keras.saving.load_model('fizzbuzz_mnist_single.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f4c04-53b6-4e9d-ad4e-4e25c5a19edd",
   "metadata": {},
   "source": [
    "# Step 2: Create super model with cloned models\n",
    "\n",
    "Create two separate MNIST evaluators that will feed into a concatenator, followed by a dense group to calculate the Fizzbuzz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "635795cc-6bca-4d63-ad4c-f50b9934b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the existing layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# We will clone the MNIST model to use it twice\n",
    "model._name = 'copy1'\n",
    "base_model1 = clone_model(model)\n",
    "model._name = 'copy2'\n",
    "base_model2 = clone_model(model)\n",
    "\n",
    "# Load the previously trained weights\n",
    "base_model1.set_weights(model.get_weights())\n",
    "base_model2.set_weights(model.get_weights())\n",
    "\n",
    "# Freeze the existing layers\n",
    "for layer in base_model1.layers: layer.trainable = False\n",
    "for layer in base_model2.layers: layer.trainable = False\n",
    "\n",
    "# Define the inputs for two concurrent images\n",
    "input1 = tf.keras.layers.Input(shape=(28, 28, 1), name='input1')\n",
    "input2 = tf.keras.layers.Input(shape=(28, 28, 1), name='input2')\n",
    "\n",
    "# Process each input image with the base CNN model\n",
    "output1 = base_model1(input1)\n",
    "output2 = base_model2(input2)\n",
    "\n",
    "# Concatenate the outputs from the two models\n",
    "combined = tf.keras.layers.Concatenate()([output1, output2])\n",
    "\n",
    "# Adding dense layers to interpret Fizzbuzz\n",
    "combined = tf.keras.layers.Flatten()(combined)\n",
    "dense_output = tf.keras.layers.Dense(100, activation='sigmoid')(combined)\n",
    "dense_output = tf.keras.layers.Dense(20, activation='relu')(dense_output)\n",
    "dense_output = tf.keras.layers.Flatten()(dense_output)\n",
    "dense_output = tf.keras.layers.Dense(2, activation='sigmoid')(dense_output)\n",
    "\n",
    "# Create the new model with dual inputs\n",
    "super_model = Model(inputs=[input1, input2], outputs=dense_output)\n",
    "\n",
    "# Compile the model with appropriate loss and optimizer\n",
    "super_model.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['binary_accuracy'], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31511ef-f433-4199-8e23-cb1b3615c8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  Trainable  \n",
      "=============================================================================================================\n",
      " input1 (InputLayer)         [(None, 28, 28, 1)]          0         []                            Y          \n",
      "                                                                                                             \n",
      " input2 (InputLayer)         [(None, 28, 28, 1)]          0         []                            Y          \n",
      "                                                                                                             \n",
      " copy1 (Sequential)          (None, 10)                   2213610   ['input1[0][0]']              Y          \n",
      "                                                                                                             \n",
      " copy2 (Sequential)          (None, 10)                   2213610   ['input2[0][0]']              Y          \n",
      "                                                                                                             \n",
      " concatenate_1 (Concatenate  (None, 20)                   0         ['copy1[0][0]',               Y          \n",
      " )                                                                   'copy2[0][0]']                          \n",
      "                                                                                                             \n",
      " flatten_1 (Flatten)         (None, 20)                   0         ['concatenate_1[0][0]']       Y          \n",
      "                                                                                                             \n",
      " dense_3 (Dense)             (None, 100)                  2100      ['flatten_1[0][0]']           Y          \n",
      "                                                                                                             \n",
      " dense_4 (Dense)             (None, 20)                   2020      ['dense_3[0][0]']             Y          \n",
      "                                                                                                             \n",
      " flatten_2 (Flatten)         (None, 20)                   0         ['dense_4[0][0]']             Y          \n",
      "                                                                                                             \n",
      " dense_5 (Dense)             (None, 2)                    42        ['flatten_2[0][0]']           Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 4431382 (16.90 MB)\n",
      "Trainable params: 4162 (16.26 KB)\n",
      "Non-trainable params: 4427220 (16.89 MB)\n",
      "_____________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "super_model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c51fa3b-19f4-4372-bc81-e4b5d45141a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data, if necessary\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255\n",
    "\n",
    "\n",
    "def generate_batch(): # debug=False):\n",
    "    \"\"\"\n",
    "    Creates a batch from numbers 00 to 99.\n",
    "\n",
    "    For every number, picks two random representative digits, \n",
    "      calculates its fizzbuzz, returns the output.\n",
    "    \"\"\"\n",
    "\n",
    "    # inputs = []\n",
    "    inputs1 = []\n",
    "    inputs2 = []\n",
    "    labels = []\n",
    "    number_locations = {}\n",
    "    \n",
    "    batch = 5 # number of sequences from 1 to 100 to be generated\n",
    "    \n",
    "    # find and organize digits\n",
    "    for i in range(10):\n",
    "        number_locations[i] = np.where(y_train == i)[0]\n",
    "\n",
    "    for b in range(batch):\n",
    "        for i in range(0, 100):\n",
    "            tens = int(i / 10)\n",
    "            ones = i % 10\n",
    "        \n",
    "            # pick an image from the list of digits\n",
    "            first_digit  = number_locations[tens][np.random.choice(len(number_locations[tens]), size=1)][0]\n",
    "            second_digit = number_locations[ones][np.random.choice(len(number_locations[ones]), size=1)][0]\n",
    "            \n",
    "            img0 = x_train[first_digit]\n",
    "            img1 = x_train[second_digit]\n",
    "    \n",
    "            inputs1.append(img0)\n",
    "            inputs2.append(img1)\n",
    "            \n",
    "    \n",
    "            # Fizzbuzz classification\n",
    "            fizz = 0\n",
    "            buzz = 0\n",
    "            if i % 3 == 0: fizz = 1\n",
    "            if i % 5 == 0: buzz = 1\n",
    "    \n",
    "            # create fizzbuzz labels\n",
    "            label = np.array([fizz, buzz]) #.reshape(2,1)\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "    # Shuffle the output list \n",
    "    temp = list(zip(inputs1, inputs2, labels))\n",
    "    random.shuffle(temp)\n",
    "    inputs1, inputs2, labels = zip(*temp)\n",
    "    inputs1, inputs2, labels = list(inputs1), list(inputs2), list(labels) \n",
    "\n",
    "    # Clean up outputs\n",
    "    inputs1 = np.array(inputs1)\n",
    "    inputs2 = np.array(inputs2)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return inputs1, inputs2, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f80f2a1d-6159-4c66-afa0-28b00b7397b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 6s 28ms/step - loss: 0.5453 - binary_accuracy: 0.7300\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4266 - binary_accuracy: 0.7868\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3338 - binary_accuracy: 0.8293\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3071 - binary_accuracy: 0.8458\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2731 - binary_accuracy: 0.8985\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2037 - binary_accuracy: 0.9146\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.1229 - binary_accuracy: 0.9814\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0694 - binary_accuracy: 0.9883\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0462 - binary_accuracy: 0.9965\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0330 - binary_accuracy: 0.9966\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0254 - binary_accuracy: 0.9969\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0219 - binary_accuracy: 0.9969\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0213 - binary_accuracy: 0.9964\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0188 - binary_accuracy: 0.9969\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0190 - binary_accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f72207c6190>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_generator():\n",
    "    \"\"\"\n",
    "    Creates back to back sequences of fizzbuzz calculations, in batches, from 00 to 99\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Generate batch of inputs and labels\n",
    "        inputs1, inputs2, labels = generate_batch()  # Replace with your function\n",
    "        yield [inputs1, inputs2], labels\n",
    "\n",
    "# Use generator with fit()\n",
    "super_model.fit(data_generator(), steps_per_epoch=100, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68ca3fb3-77a7-4bea-b01a-5a83c9f33ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fizzbuzz_mnist_fizzbuzz.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd79954-40f5-42fb-a905-5885baf992cd",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "Select two values from the testing data, and infer the fizzbuzz output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec09295c-4229-4382-99f1-0de1d9168b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[0.95226836 0.99980813]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_digits(value):\n",
    "    \"\"\"\n",
    "    Select two MNIST values from the testing data to feed to the fizzbuzz calculator.\n",
    "    \"\"\"\n",
    "    \n",
    "    # find and organize digits\n",
    "    number_locations = {}\n",
    "\n",
    "    for i in range(10):\n",
    "        number_locations[i] = np.where(y_test == i)[0]\n",
    "\n",
    "    tens = int(value / 10)\n",
    "    ones = value % 10\n",
    "\n",
    "    # pick an image from the list of digits\n",
    "    first_digit  = number_locations[tens][np.random.choice(len(number_locations[tens]), size=1)][0]\n",
    "    second_digit = number_locations[ones][np.random.choice(len(number_locations[ones]), size=1)][0]\n",
    "    \n",
    "    img0 = x_test[first_digit]\n",
    "    img1 = x_test[second_digit]\n",
    "\n",
    "    return np.expand_dims(img0, axis=0), np.expand_dims(img1, axis=0)\n",
    "\n",
    "\n",
    "# Pick a random number\n",
    "x = random.randint(0,100)\n",
    "\n",
    "# retrieve two digit pictures\n",
    "first_digit, second_digit = get_digits(x)\n",
    "\n",
    "# Calculate fizzbuzz\n",
    "res = super_model.predict([first_digit, second_digit])\n",
    "print(res)\n",
    "print(\"Fizz:\", res[0][0])\n",
    "print(\"Buzz:\", res[0][1])\n",
    "\n",
    "# display value \n",
    "fig, axes = plt.subplots(1,2,figsize=(3,6))\n",
    "axes[0].imshow(first_digit[0])\n",
    "axes[1].imshow(second_digit[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756d90a5-8ea0-4176-b30d-b1ad308fae36",
   "metadata": {},
   "source": [
    "Run through all digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2709f-c18c-40e3-9771-25d09c25b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # retrieve two digit pictures\n",
    "    first_digit, second_digit = get_digits(x)\n",
    "    \n",
    "    # Calculate fizzbuzz\n",
    "    res = super_model.predict([first_digit, second_digit])\n",
    "    print(i, \"Fizz:\", res[0][0], \"Buzz:\", res[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
